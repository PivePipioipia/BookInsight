{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T16:18:04.644320Z",
     "start_time": "2025-10-10T16:17:38.992664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.retriever.text_image_retriever import TextImageRetriever\n",
    "from src.retriever.smart_retriever import SmartRetriever\n",
    "\n",
    "retriever = TextImageRetriever(\n",
    "    text_index_path=\"D:/BookInsight/data/vectorstores/text_faiss/shard_0/index.faiss\",\n",
    "    text_meta_path=\"D:/BookInsight/data/vectorstores/text_faiss/shard_0/index.pkl\",\n",
    "    image_index_path=\"D:/BookInsight/data/vectorstores/image_faiss/shard_0/index.faiss\",\n",
    "    image_meta_path=\"D:/BookInsight/data/vectorstores/image_faiss/shard_0/index.pkl\",\n",
    ")\n",
    "retriever.load_stores()\n",
    "\n",
    "smart = SmartRetriever(retriever)\n",
    "results = smart.search_multimodal(\"children's fantasy about dragons\", n_expand=3, k=5)\n",
    "\n",
    "for r in results:\n",
    "    src = r[\"source\"].upper()\n",
    "    title = r[\"metadata\"].get(\"title\")\n",
    "    print(f\"[{src}] {title} | score={r['fused_score']:.4f}\")\n"
   ],
   "id": "1754a7f3d7024b96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading text FAISS store...\n",
      "üì¶ Loading FAISS index from D:/BookInsight/data/vectorstores/text_faiss/shard_0/index.faiss ...\n",
      "‚úÖ Loaded FAISS index with 88956 vectors.\n",
      "üìò Loading metadata from D:/BookInsight/data/vectorstores/text_faiss/shard_0/index.pkl ...\n",
      "‚ö†Ô∏è Detected LangChain FAISS tuple ‚Äî extracting InMemoryDocstore...\n",
      "‚úÖ Metadata rows match FAISS index: 88956 entries.\n",
      "üéØ Loaded TEXT store successfully!\n",
      "\n",
      " Loading image FAISS store...\n",
      "üì¶ Loading FAISS index from D:/BookInsight/data/vectorstores/image_faiss/shard_0/index.faiss ...\n",
      "‚úÖ Loaded FAISS index with 4882 vectors.\n",
      "üìò Loading metadata from D:/BookInsight/data/vectorstores/image_faiss/shard_0/index.pkl ...\n",
      "‚úÖ Metadata rows match FAISS index: 4882 entries.\n",
      "üéØ Loaded IMAGE store successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Loading Mistral-7B-Instruct model for query expansion...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a33dbcc612ae42afa269aedf4848daa1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\envs\\book\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\PC\\.cache\\huggingface\\hub\\models--mistralai--Mistral-7B-Instruct-v0.2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "[WARNING]  Could not load Mistral locally: Could not load model mistralai/Mistral-7B-Instruct-v0.2 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForCausalLM'>, <class 'transformers.models.mistral.modeling_mistral.MistralForCausalLM'>). See the original errors:\n",
      "\n",
      "while loading with AutoModelForCausalLM, an error is thrown:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PC\\anaconda3\\envs\\book\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 293, in infer_framework_load_model\n",
      "    model = model_class.from_pretrained(model, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PC\\anaconda3\\envs\\book\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 604, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PC\\anaconda3\\envs\\book\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 288, in _wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PC\\anaconda3\\envs\\book\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4936, in from_pretrained\n",
      "    raise ValueError(\n",
      "ValueError: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PC\\anaconda3\\envs\\book\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 311, in infer_framework_load_model\n",
      "    model = model_class.from_pretrained(model, **fp32_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PC\\anaconda3\\envs\\book\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 604, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PC\\anaconda3\\envs\\book\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 288, in _wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PC\\anaconda3\\envs\\book\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4936, in from_pretrained\n",
      "    raise ValueError(\n",
      "ValueError: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`\n",
      "\n",
      "while loading with MistralForCausalLM, an error is thrown:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PC\\anaconda3\\envs\\book\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 293, in infer_framework_load_model\n",
      "    model = model_class.from_pretrained(model, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PC\\anaconda3\\envs\\book\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 288, in _wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PC\\anaconda3\\envs\\book\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4936, in from_pretrained\n",
      "    raise ValueError(\n",
      "ValueError: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PC\\anaconda3\\envs\\book\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 311, in infer_framework_load_model\n",
      "    model = model_class.from_pretrained(model, **fp32_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PC\\anaconda3\\envs\\book\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 288, in _wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PC\\anaconda3\\envs\\book\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4936, in from_pretrained\n",
      "    raise ValueError(\n",
      "ValueError: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`\n",
      "\n",
      "\n",
      "\n",
      "[WARNING] Falling back to simple rule-based paraphraser.\n",
      "[INFO] Generated 3 query variants:\n",
      "[INFO]   ‚Ä¢ children's fantasy about dragons\n",
      "[INFO]   ‚Ä¢ kids's fantasy about dragons\n",
      "[INFO]   ‚Ä¢ children's adventure about dragons\n",
      "[INFO]  Searching for variant: 'children's fantasy about dragons'\n",
      "[INFO] Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BGE encoder (BAAI/bge-small-en-v1.5)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fbb4d6b01982418686fd21a7f5716f7b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Load pretrained SentenceTransformer: clip-ViT-B-16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Loading CLIP text encoder (clip-ViT-B-16)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f1d53eb591a40388bf9828c60d2aaae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]  Searching for variant: 'kids's fantasy about dragons'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f258605766f84ace9ed9915799192eb7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e84860179a8e4a00b86a68173c1b28e1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]  Searching for variant: 'children's adventure about dragons'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62c1049b1d154d5a9ecc5027964a3551"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e5a18ccf9a14a46a26a14a165fed57b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]  Fused 10 total results from 3 query variants.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEXT] None | score=0.0164\n",
      "[TEXT] None | score=0.0164\n",
      "[TEXT] None | score=0.0164\n",
      "[IMAGE] DRAGONS KINGS DRAGONLING 6 | score=0.0164\n",
      "[IMAGE] Beware the Crystal Dragon | score=0.0164\n",
      "[IMAGE] Beware the Crystal Dragon | score=0.0164\n",
      "[TEXT] None | score=0.0161\n",
      "[TEXT] None | score=0.0161\n",
      "[TEXT] None | score=0.0161\n",
      "[IMAGE] Beware the Crystal Dragon | score=0.0161\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
